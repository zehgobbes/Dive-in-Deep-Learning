{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe0fdf2-6159-4663-8d71-dfcb13ec0983",
   "metadata": {},
   "source": [
    "# 6.4. Lazy Initialization\n",
    "\n",
    "Lazy = preguiçosa\n",
    "\n",
    "Até agora, pode parecer que escapamos impunes ao sermos desleixados na configuração de nossas redes. Especificamente, fizemos as seguintes coisas não intuitivas, que podem não parecer que deveriam funcionar:\n",
    "\n",
    "- Definimos as arquiteturas de rede sem especificar a dimensionalidade de entrada.\n",
    "\n",
    "- Adicionamos camadas sem especificar a dimensão de saída da camada anterior.\n",
    "\n",
    "- Nós até mesmo “inicializamos” esses parâmetros antes de fornecer informações suficientes para determinar quantos parâmetros nossos modelos deveriam conter.\n",
    "\n",
    "Você pode se surpreender que nosso código seja executado. Afinal, não há como o framework de aprendizado profundo dizer qual seria a dimensionalidade de entrada de uma rede. O truque aqui é que o framework adia a inicialização , esperando até a primeira vez que passamos dados pelo modelo, para inferir os tamanhos de cada camada na hora.\n",
    "\n",
    "Mais tarde, ao trabalhar com redes neurais convolucionais, essa técnica se tornará ainda mais conveniente, pois a dimensionalidade de entrada (por exemplo, a resolução de uma imagem) afetará a dimensionalidade de cada camada subsequente. Portanto, a capacidade de definir parâmetros sem a necessidade de saber, no momento da escrita do código, o valor da dimensão pode simplificar muito a tarefa de especificar e, subsequentemente, modificar nossos modelos. Em seguida, nos aprofundamos na mecânica da inicialização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0dfcfd-6937-4c2b-84b9-79316c9e5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d495644-8f62-4632-bbaa-937354cd04ad",
   "metadata": {},
   "source": [
    "Para começar, vamos instanciar um MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73595032-f932-4d9b-baaa-153f76944350",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(256),     # out=256; in não inicializado (por isso é preguiçosa)\n",
    "                    nn.ReLU(), \n",
    "                    nn.LazyLinear(10))     # out=10; in não inicializado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d13df6-fe31-4f48-bbc3-e446337c5cb4",
   "metadata": {},
   "source": [
    "__Neste ponto, a rede não pode saber as dimensões dos pesos da camada de entrada porque a dimensão de entrada permanece desconhecida.__\n",
    "Consequentemente, o framework ainda não inicializou nenhum parâmetro. Confirmamos tentando acessar os parâmetros abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4ffc75-6a0d-4c13-b32c-d116c23c9b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight', <UninitializedParameter>),\n",
       " ('0.bias', <UninitializedParameter>),\n",
       " ('2.weight', <UninitializedParameter>),\n",
       " ('2.bias', <UninitializedParameter>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param) for name, param in net.named_parameters()] # param.shape não pode ser inicializado (UninitializedParameter) pois\n",
    "                                                          # não se sabe a dimensão da entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "944ad541-a3b3-4603-b054-db04faa85d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', <UninitializedParameter>),\n",
       "             ('bias', <UninitializedParameter>)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].state_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f63e4f-0ed7-4fc7-899a-ff81882d133b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<UninitializedParameter>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1077a11-3435-4cb4-9027-9e800592b136",
   "metadata": {},
   "source": [
    "Em seguida, vamos passar dados pela rede para que o framework finalmente inicialize os parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e10f65ee-ef5b-49eb-9f85-2bb2c32dec79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 20])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2, 20)\n",
    "net(X)\n",
    "\n",
    "net[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e17520-0d68-4140-ad86-ed0882d23130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1764, -0.0312,  0.1332,  ..., -0.2085,  0.1282, -0.1506],\n",
       "        [-0.0541,  0.0656,  0.0547,  ...,  0.0935,  0.0461, -0.1254],\n",
       "        [ 0.0390,  0.1964,  0.1284,  ...,  0.1928,  0.0656,  0.1535],\n",
       "        ...,\n",
       "        [-0.1563, -0.1202,  0.1623,  ..., -0.1768, -0.0481, -0.0682],\n",
       "        [-0.1600,  0.0095, -0.0811,  ..., -0.1861, -0.2071, -0.1281],\n",
       "        [ 0.1852, -0.1985,  0.1667,  ..., -0.0451,  0.0840, -0.1559]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd6adbe-f5d2-4bcd-ad3a-7354c88e4353",
   "metadata": {},
   "source": [
    "Assim que sabemos a dimensionalidade de entrada, 20, o framework pode identificar o formato da matriz de peso da primeira camada inserindo o valor 20. Tendo reconhecido o formato da primeira camada, o framework prossegue para a segunda camada, e assim por diante pelo gráfico computacional até que todos os formatos sejam conhecidos. Observe que, neste caso, apenas a primeira camada requer inicialização preguiçosa (lazy initialization), mas o framework inicializa sequencialmente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9980416a-5139-4f3a-8a4d-1d952effdc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.1764, -0.0312,  0.1332,  ..., -0.2085,  0.1282, -0.1506],\n",
       "                      [-0.0541,  0.0656,  0.0547,  ...,  0.0935,  0.0461, -0.1254],\n",
       "                      [ 0.0390,  0.1964,  0.1284,  ...,  0.1928,  0.0656,  0.1535],\n",
       "                      ...,\n",
       "                      [-0.1563, -0.1202,  0.1623,  ..., -0.1768, -0.0481, -0.0682],\n",
       "                      [-0.1600,  0.0095, -0.0811,  ..., -0.1861, -0.2071, -0.1281],\n",
       "                      [ 0.1852, -0.1985,  0.1667,  ..., -0.0451,  0.0840, -0.1559]])),\n",
       "             ('0.bias',\n",
       "              tensor([ 0.1495, -0.2089, -0.0306, -0.1353,  0.0119,  0.2185, -0.1546,  0.0699,\n",
       "                       0.1010, -0.1609, -0.0339,  0.1757,  0.0913, -0.0989, -0.1393,  0.2023,\n",
       "                      -0.0366,  0.0281,  0.2025,  0.1631,  0.1626, -0.0452, -0.1678, -0.1703,\n",
       "                       0.0532, -0.0869, -0.1046,  0.0229, -0.1678, -0.0026,  0.0524, -0.2209,\n",
       "                       0.1722,  0.0615, -0.2155,  0.0510,  0.0310,  0.1495,  0.1657,  0.1961,\n",
       "                       0.1387,  0.0196, -0.2222, -0.2203,  0.1461,  0.1237, -0.2008, -0.1164,\n",
       "                       0.1616, -0.0019, -0.0245, -0.1084, -0.0306,  0.0043, -0.0313, -0.0325,\n",
       "                      -0.1096,  0.2057, -0.1331, -0.0790, -0.0985,  0.1756, -0.0390, -0.0153,\n",
       "                      -0.0822, -0.1662,  0.2029, -0.1124,  0.0315,  0.0393,  0.1204,  0.1193,\n",
       "                      -0.0885,  0.1570,  0.0157, -0.1905,  0.1885, -0.1728,  0.2126,  0.1149,\n",
       "                      -0.1696, -0.2186, -0.0307, -0.0377,  0.0954, -0.0220, -0.1193,  0.1347,\n",
       "                       0.2115,  0.0675, -0.1599, -0.2025,  0.1041, -0.1906, -0.0563,  0.2152,\n",
       "                      -0.1839,  0.0199,  0.0162, -0.0141, -0.1804, -0.1237,  0.0717, -0.2136,\n",
       "                       0.0208,  0.0223,  0.2198,  0.0323,  0.0108,  0.1393,  0.1129,  0.1859,\n",
       "                      -0.0505,  0.1898,  0.0909, -0.0033,  0.1012, -0.1669, -0.1173,  0.1998,\n",
       "                      -0.1124,  0.0729,  0.1727,  0.0793, -0.0332,  0.1856,  0.0877, -0.1825,\n",
       "                      -0.1283,  0.2132,  0.1728, -0.1298,  0.0885, -0.1348, -0.2148,  0.0723,\n",
       "                      -0.1334, -0.2063, -0.1680,  0.1548,  0.0710, -0.2154,  0.0086, -0.1285,\n",
       "                      -0.1707,  0.2010,  0.0475, -0.0078, -0.1479, -0.0781, -0.0870,  0.1565,\n",
       "                       0.1693, -0.1370,  0.1553, -0.0715, -0.0274,  0.0176, -0.1291, -0.1923,\n",
       "                      -0.0168,  0.2015, -0.0246,  0.1034,  0.1067,  0.1333, -0.1473,  0.0269,\n",
       "                       0.1037,  0.0885,  0.1977,  0.0578,  0.0809, -0.1884,  0.1170,  0.0273,\n",
       "                      -0.0969,  0.1155,  0.0135,  0.1954,  0.1301,  0.0005, -0.0858,  0.0865,\n",
       "                       0.1244,  0.1644,  0.1546, -0.0957,  0.1401,  0.1127,  0.0088,  0.0298,\n",
       "                       0.1958, -0.1957, -0.1796, -0.2035, -0.1218,  0.0679, -0.0613, -0.0347,\n",
       "                      -0.1495, -0.0335, -0.1307,  0.1760,  0.2197,  0.0976, -0.1374, -0.1560,\n",
       "                       0.1634, -0.2028,  0.0409,  0.1780,  0.2161, -0.0521, -0.0805, -0.1859,\n",
       "                      -0.1768,  0.1625,  0.1255, -0.0279,  0.1056,  0.1118,  0.1546,  0.1296,\n",
       "                      -0.1878, -0.1059, -0.1895, -0.0835,  0.0294, -0.1792,  0.0757,  0.0222,\n",
       "                       0.0659, -0.0808, -0.2184,  0.0387,  0.1249,  0.1099, -0.0970,  0.0220,\n",
       "                       0.0553,  0.1048, -0.1778, -0.0317, -0.1926, -0.1480,  0.0042, -0.1676,\n",
       "                       0.1426, -0.0140,  0.1945,  0.1840,  0.1208,  0.0692,  0.0948, -0.0555])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 3.7769e-02,  3.7524e-02,  5.3713e-03,  ..., -1.9304e-04,\n",
       "                       -3.0046e-02,  1.8849e-02],\n",
       "                      [-2.5282e-02, -3.2826e-02, -5.7111e-03,  ...,  1.0093e-02,\n",
       "                       -1.5699e-02, -3.8318e-02],\n",
       "                      [-5.0534e-02, -5.9881e-02,  2.2775e-02,  ..., -6.2779e-05,\n",
       "                       -5.9994e-02, -3.3080e-02],\n",
       "                      ...,\n",
       "                      [ 5.7205e-02,  1.6184e-02,  1.1999e-02,  ...,  1.5008e-02,\n",
       "                        5.0115e-02,  4.3119e-02],\n",
       "                      [-5.6529e-02,  1.4948e-02, -6.0255e-02,  ...,  3.0098e-03,\n",
       "                        2.4272e-03, -3.4087e-02],\n",
       "                      [-6.0354e-02, -5.7350e-03, -1.9231e-02,  ..., -5.0508e-02,\n",
       "                        5.8563e-02, -3.9799e-02]])),\n",
       "             ('2.bias',\n",
       "              tensor([-0.0314,  0.0242,  0.0007, -0.0109,  0.0012,  0.0221, -0.0550, -0.0315,\n",
       "                       0.0098, -0.0487]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1fa282-2580-4ded-ad2e-acbfbdf44c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight', torch.Size([256, 20])),\n",
       " ('0.bias', torch.Size([256])),\n",
       " ('2.weight', torch.Size([10, 256])),\n",
       " ('2.bias', torch.Size([10]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param.shape) for name, param in net.named_parameters()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247b5ab-e04f-4a71-9262-228433e83d93",
   "metadata": {},
   "source": [
    "O método a seguir passa entradas fictícias pela rede para uma execução a seco para inferir todas as formas de parâmetros e subsequentemente inicializa os parâmetros. Ele será usado mais tarde quando inicializações aleatórias padrão não forem desejadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3b61496-d11d-4ea6-bb91-b895ec6e788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.Module)  #@save\n",
    "def apply_init(self, inputs, init=None):\n",
    "    self.forward(*inputs)\n",
    "    if init is not None:\n",
    "        self.net.apply(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec9cde-1aae-4818-afac-85b2762bcfaa",
   "metadata": {},
   "source": [
    "# 6.4.1. Resumo\n",
    "\n",
    "A inicialização preguiçosa (sem inicializar entradas, apenas saídas) pode ser conveniente, permitindo que o framework infira formas de parâmetros automaticamente, facilitando a modificação de arquiteturas e eliminando uma fonte comum de erros. Podemos passar dados pelo modelo (fazer net(X)) para fazer o framework finalmente inicializar os parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46dbb93-51c3-45da-ab99-059312ccd787",
   "metadata": {},
   "source": [
    "# 6.4.2. Exercícios\n",
    "\n",
    "# Ex. 1 - O que acontece se você especificar as dimensões de entrada para a primeira camada, mas não para as camadas subsequentes? Você obtém inicialização imediata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "832b7740-b170-4e37-95a8-b3e675522a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5999e-02,  1.1579e+00, -6.6829e-02, -4.8113e-01, -9.6888e-02,\n",
       "         -4.7763e-01,  3.5814e-01, -2.8906e-01, -4.3587e-01,  8.3621e-01,\n",
       "         -2.7230e-01, -9.9133e-03, -2.1856e-01,  2.1296e-02, -8.0526e-01,\n",
       "         -1.2539e-02, -1.2116e-01, -2.5448e-01,  7.4097e-01, -5.4865e-01,\n",
       "         -4.8688e-01, -5.0381e-01, -3.8352e-01, -3.5394e-01, -4.2473e-03,\n",
       "         -1.2277e-02,  4.4227e-01, -9.9328e-01, -5.4534e-02,  4.7397e-01,\n",
       "          2.1136e-01,  4.9253e-02,  5.4018e-02,  3.7261e-01,  7.6454e-03,\n",
       "         -7.5679e-02,  1.9628e-01,  3.2247e-01, -6.7219e-01,  1.9240e-01,\n",
       "          2.3901e-01, -1.3985e-01, -3.4483e-02,  5.7895e-02,  1.5708e-01,\n",
       "          1.0999e-01, -3.9320e-01, -1.3569e-01,  9.8050e-01,  2.2505e-02,\n",
       "         -7.1109e-01, -1.2067e-01, -3.0946e-01, -7.9308e-02,  2.3654e-01,\n",
       "         -4.1967e-01, -3.2983e-01,  7.5846e-01, -5.8786e-01, -5.4799e-01,\n",
       "         -2.4840e-01, -3.0474e-01, -5.6555e-02, -1.0236e-01, -2.7964e-01,\n",
       "         -3.4616e-01, -4.0941e-01, -8.6305e-02,  2.1650e-01, -7.6002e-02,\n",
       "         -5.3818e-01, -4.6712e-02,  3.4870e-01,  1.2385e-01,  2.0662e-01,\n",
       "          4.8439e-01,  3.1026e-01,  5.2041e-01,  1.9241e-02, -5.2574e-01,\n",
       "         -1.8580e-01, -2.6043e-02,  1.9727e-01, -3.9617e-01,  1.6155e-01,\n",
       "          2.5592e-01,  8.0648e-02, -3.3209e-01, -5.7685e-01,  1.4892e-01,\n",
       "          4.1471e-01, -8.8582e-02, -9.3982e-04,  2.9560e-01,  1.8852e-01,\n",
       "          3.0888e-02,  3.5723e-03,  2.6375e-02,  5.1763e-02, -3.4532e-01,\n",
       "          3.7066e-01, -4.1850e-02, -1.8042e-01, -5.6834e-02, -4.9732e-01,\n",
       "          2.5004e-03, -4.1398e-01,  7.5333e-01,  1.2497e-01,  4.9026e-01,\n",
       "          2.8837e-01, -2.9619e-01,  5.1882e-02,  3.4471e-01,  2.3718e-01,\n",
       "         -6.2661e-01, -1.5282e-01, -3.8471e-01, -3.0912e-01,  4.9923e-01,\n",
       "         -7.9403e-02,  3.2641e-01,  9.4146e-02,  3.5448e-01,  1.1131e-01,\n",
       "         -3.4371e-01,  4.6616e-01,  7.0612e-01, -1.5937e-01, -1.7508e-01,\n",
       "         -1.8098e-01, -2.5455e-01,  4.8999e-02,  4.0100e-02,  1.5942e-01,\n",
       "          1.8284e-01,  2.3242e-01, -4.2216e-02, -4.2467e-01,  5.8479e-02,\n",
       "          4.0518e-01, -5.8699e-01,  1.7085e-01,  3.1561e-01,  3.1214e-01,\n",
       "         -3.8821e-01, -2.8411e-01, -4.9433e-02, -8.0453e-02,  2.3051e-01,\n",
       "          9.2170e-02, -2.3774e-01,  3.0847e-01, -2.5145e-01, -2.7208e-01,\n",
       "          4.5919e-01, -5.5856e-01,  7.4668e-01,  7.1459e-01,  9.1619e-02,\n",
       "          1.3793e-01, -3.8578e-01,  4.5017e-01, -2.4673e-01, -6.0239e-02,\n",
       "          9.2845e-01, -1.9344e-01, -3.0955e-03,  5.5791e-01,  1.2868e-01,\n",
       "          3.9482e-02,  4.1471e-01,  2.3799e-02, -1.3491e-01, -3.8240e-01,\n",
       "          5.1964e-02,  4.2018e-04, -3.9597e-02,  3.9324e-01, -1.0310e-01,\n",
       "          4.4928e-04, -1.0957e+00,  6.7388e-02, -8.5602e-02,  3.5480e-01,\n",
       "          1.1351e-01,  1.0868e-01, -5.2574e-02,  1.7456e-02, -1.5193e-02,\n",
       "          5.5466e-01,  4.1254e-01,  1.0355e+00,  2.2584e-01, -5.3494e-02,\n",
       "          1.3490e-01, -7.8537e-02,  1.0827e-01, -5.9167e-01,  3.2238e-01,\n",
       "         -4.6299e-01, -8.9716e-02,  1.6534e-01, -1.1259e+00, -7.0107e-01,\n",
       "          1.8350e-01,  8.2491e-02,  3.3656e-01, -8.5788e-02,  2.1281e-01,\n",
       "         -2.0080e-02,  1.2168e-01,  3.2711e-01,  1.0668e-01,  6.3165e-02,\n",
       "          1.6185e-01, -1.1066e+00, -6.4201e-02, -3.7217e-01,  6.1164e-02,\n",
       "          1.3131e-01, -4.6637e-02,  8.9589e-02, -4.9605e-01,  1.0267e-01,\n",
       "         -8.6486e-02, -3.0119e-01,  2.5870e-01, -2.0556e-01, -2.6571e-01,\n",
       "          4.4717e-01, -3.4090e-01,  2.8458e-01,  2.4874e-01,  2.8523e-01,\n",
       "          1.4679e-01,  1.6153e-03, -2.2882e-01,  1.3594e-01, -7.0945e-01,\n",
       "         -5.9032e-02, -3.0248e-01, -4.5255e-01,  2.8669e-01, -2.0517e-01,\n",
       "         -3.0133e-01, -1.4655e-01, -3.1944e-01, -5.6088e-01,  2.5826e-01,\n",
       "          4.5112e-01, -5.3898e-03,  7.8489e-01, -1.0819e-01, -6.6254e-01,\n",
       "         -4.4567e-01],\n",
       "        [ 4.1356e-02,  1.1029e+00, -2.9454e-01, -4.0456e-01,  3.1876e-01,\n",
       "         -3.7366e-01,  2.0580e-01, -2.6654e-01, -4.3839e-01,  5.9423e-01,\n",
       "         -1.6297e-01, -1.9656e-01, -4.0866e-01, -3.7005e-01, -8.3932e-01,\n",
       "          1.1293e-01, -8.0508e-02, -1.8679e-01,  8.2838e-01, -8.7581e-01,\n",
       "         -6.2713e-01, -4.0242e-01, -3.2501e-01, -3.7035e-01,  1.4737e-01,\n",
       "         -4.0893e-02,  5.7382e-01, -1.0125e+00,  5.3656e-04,  3.8281e-01,\n",
       "          2.4488e-01, -1.7317e-01,  1.7767e-01,  8.7707e-02,  2.6569e-02,\n",
       "          1.3446e-01,  4.2981e-02,  3.6905e-01, -4.9844e-01, -4.0397e-02,\n",
       "          6.8079e-01, -2.1453e-01,  8.4734e-02,  2.4061e-01,  1.3925e-01,\n",
       "          1.7717e-01, -3.3766e-01, -4.9759e-02,  9.3125e-01,  1.8429e-01,\n",
       "         -2.6791e-01, -1.2170e-01, -1.4683e-01, -3.2452e-01,  2.8033e-01,\n",
       "         -4.9194e-01, -1.1529e-01,  4.4873e-01, -9.3102e-01, -9.8410e-01,\n",
       "          1.4243e-01, -1.9171e-01, -3.1386e-01,  1.3455e-01, -1.5136e-01,\n",
       "         -3.6753e-01, -4.5802e-01, -2.0679e-01,  2.8845e-01, -2.7329e-01,\n",
       "         -9.0791e-01, -2.5718e-01,  4.0577e-01,  8.6016e-02, -6.9179e-02,\n",
       "          3.4582e-01,  8.1006e-02,  6.2731e-01, -1.7984e-01, -7.1876e-01,\n",
       "         -3.4784e-01,  1.8302e-01,  4.6343e-01, -3.9765e-01, -8.7318e-03,\n",
       "         -1.7206e-01,  1.8179e-01, -3.2164e-01, -7.8297e-01,  4.4225e-01,\n",
       "          3.2096e-01, -1.0711e-02, -2.1125e-01,  8.9825e-02, -7.0805e-02,\n",
       "         -1.6713e-01, -1.0522e-01,  1.5812e-01, -2.7966e-01, -3.2826e-01,\n",
       "          4.9558e-01,  1.8791e-01,  1.6467e-02, -8.2813e-02, -4.8701e-01,\n",
       "          7.4196e-02, -5.9245e-01,  8.0409e-01,  5.1651e-02,  5.2051e-01,\n",
       "          2.0882e-01, -2.8035e-01,  3.1023e-01,  3.6764e-01,  1.3495e-01,\n",
       "         -2.1786e-01,  3.2713e-02, -6.0705e-01, -1.3234e-01,  7.3233e-01,\n",
       "         -5.1982e-02,  1.0165e-01,  2.7390e-02,  2.5975e-01, -4.5826e-02,\n",
       "         -2.9115e-01,  5.2111e-01,  5.7044e-01, -3.1076e-01,  2.0196e-01,\n",
       "         -2.2821e-01, -1.9915e-01,  1.9660e-01,  6.3754e-02, -5.9884e-02,\n",
       "          3.2326e-01,  5.6415e-01,  2.3435e-01, -4.9603e-01,  1.7297e-01,\n",
       "          4.6774e-01, -6.5412e-01,  3.6661e-01,  2.3714e-01,  3.3743e-01,\n",
       "          8.3272e-02, -3.9096e-01,  4.6597e-02,  2.4453e-01,  7.4017e-02,\n",
       "          2.4200e-01, -1.6629e-01, -1.7306e-01, -2.0052e-01,  2.1609e-02,\n",
       "          2.7975e-01, -8.8734e-01,  7.2289e-01,  8.8924e-01, -2.5933e-01,\n",
       "          8.8070e-02, -3.6539e-01,  5.4323e-01, -5.3310e-01, -1.0963e-01,\n",
       "          9.7161e-01, -7.2815e-02,  1.0700e-01,  5.1264e-01,  4.7992e-02,\n",
       "         -1.1628e-01,  1.5986e-02,  1.8156e-01, -2.4927e-01, -3.6778e-01,\n",
       "          4.8804e-02, -6.5798e-02,  3.3504e-01,  4.8808e-01,  6.0964e-02,\n",
       "          2.9277e-02, -1.2099e+00,  2.5017e-01, -1.4531e-01,  2.6919e-01,\n",
       "         -2.9578e-03,  1.2294e-01, -3.7786e-02,  1.2926e-01,  2.5785e-02,\n",
       "          4.9356e-01,  1.0757e-01,  7.1073e-01, -8.7662e-02, -2.6046e-01,\n",
       "          2.4953e-01, -1.4713e-01,  2.2092e-01, -4.4003e-01,  3.1565e-01,\n",
       "         -3.8353e-01, -8.3863e-02,  1.9053e-01, -8.4257e-01, -7.1024e-01,\n",
       "          1.3217e-01,  2.7939e-01,  4.5277e-01, -2.1857e-01, -1.0106e-01,\n",
       "         -4.6564e-01,  2.5940e-01, -3.0259e-02,  4.2138e-01, -1.9334e-01,\n",
       "          2.0061e-01, -1.0060e+00, -1.8606e-01, -3.0765e-01,  1.6581e-02,\n",
       "         -2.1296e-02, -1.1785e-01,  3.7403e-01, -2.9362e-01,  9.1328e-02,\n",
       "         -4.4757e-01, -2.5667e-01,  2.6119e-01,  7.1560e-02, -9.2090e-02,\n",
       "          2.9782e-01, -3.6114e-01,  1.5302e-01,  4.8365e-01,  5.3619e-02,\n",
       "          1.1660e-01, -2.0603e-02, -5.4330e-02,  1.0213e-01, -8.0576e-01,\n",
       "         -2.0444e-01, -2.6985e-02, -5.5691e-01,  4.4435e-01, -9.2029e-02,\n",
       "         -1.3355e-03, -7.3656e-02, -1.8521e-01, -6.9236e-01,  2.9608e-01,\n",
       "          5.0220e-01, -3.7642e-02,  5.5295e-01, -2.7893e-01, -4.6290e-01,\n",
       "         -3.5201e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(nn.LazyLinear(out_features=256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.LazyLinear(out_features=10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net[0](X)                # inicializando a primeira camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00938bcd-fb0f-4619-8c7f-dc25b70e71f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25043a2c-c7dc-4f1f-98a8-f30779df3bbd",
   "metadata": {},
   "source": [
    "Portanto, apenas a primeira camada é inicializada. Logo, a inicialização é imediata, entretanto, não completa, como ocorre ao fazer net(X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "734ac417-ea77-46a7-9aa5-922eee323b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1736,  0.0443,  0.2501,  0.0017, -0.1467,  0.0742,  0.0157, -0.3642,\n",
       "          0.0682, -0.0447],\n",
       "        [ 0.1509,  0.0662,  0.1918, -0.0151, -0.1127,  0.1692, -0.0116, -0.4011,\n",
       "          0.0029, -0.1410]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)            # saída y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "517ba874-c793-4686-af88-48b8f3c8a874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fe2f414-64f3-4e1f-b23d-16c8bab1cd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=256, out_features=10, bias=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56c5b9-037e-477f-b168-00d49c9df991",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c0ab8d-da1f-4f26-ba6b-c7590f4c7897",
   "metadata": {},
   "source": [
    "Modo 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "463ceaa0-1fa2-453c-a250-6187e1fc7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(nn.Linear(in_features=784,out_features=256),              # obs: Linear, não LazyLinear.\n",
    "                    nn.ReLU(),\n",
    "                    nn.LazyLinear(out_features=10))                           # possui apenas dados de saída.\n",
    "                                                                              # Linear possui dados de saída e entrada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2522021a-e3e7-4f00-8b6b-28ccfbb3ee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15e0f4ea-326d-497b-8233-bcb9a3237b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0326,  0.0092, -0.0270,  ..., -0.0194, -0.0322, -0.0268],\n",
       "          [ 0.0170,  0.0155, -0.0228,  ...,  0.0043,  0.0277,  0.0321],\n",
       "          [-0.0199, -0.0063,  0.0275,  ...,  0.0247, -0.0281, -0.0113],\n",
       "          ...,\n",
       "          [ 0.0307,  0.0003,  0.0088,  ..., -0.0246, -0.0210, -0.0014],\n",
       "          [ 0.0298, -0.0309, -0.0086,  ...,  0.0062, -0.0278,  0.0123],\n",
       "          [-0.0188,  0.0007,  0.0310,  ...,  0.0129, -0.0321,  0.0162]],\n",
       "         requires_grad=True)),\n",
       " ('0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 1.1608e-02, -2.9992e-02,  1.1081e-02,  1.9998e-02, -1.8117e-02,\n",
       "          -5.7659e-03, -2.4703e-02,  3.4264e-02, -2.3190e-02,  6.8504e-03,\n",
       "          -1.4736e-02,  3.3089e-02, -4.1488e-03,  1.5972e-02,  3.3234e-03,\n",
       "          -1.9828e-02, -8.8795e-03,  3.3190e-02,  2.6050e-02,  3.3226e-02,\n",
       "          -1.1092e-02, -8.6198e-03, -1.3684e-02, -2.4210e-02, -9.0527e-03,\n",
       "           2.8036e-02, -3.5576e-02, -2.7194e-02, -1.0425e-02,  2.9703e-02,\n",
       "           1.9163e-02, -3.0806e-02,  3.1082e-02,  1.1580e-03,  2.3546e-02,\n",
       "          -6.9460e-03, -9.2179e-04, -1.4407e-03,  2.2364e-03, -1.0596e-02,\n",
       "          -3.4102e-02, -3.1263e-02,  1.9211e-02,  9.4523e-03, -8.5183e-03,\n",
       "           2.0547e-02,  2.0130e-02,  3.3778e-02,  1.5727e-02,  2.4012e-02,\n",
       "           3.1915e-02,  2.7053e-02, -3.2338e-02, -2.9791e-02,  5.6417e-04,\n",
       "           8.7660e-04,  5.8824e-04,  2.2675e-02, -2.4731e-02,  2.6898e-02,\n",
       "          -3.6494e-03, -1.6794e-03, -4.0861e-03, -2.1322e-02,  3.0719e-02,\n",
       "           2.8004e-02,  1.3327e-02,  2.9423e-02,  2.6220e-02,  8.6799e-03,\n",
       "           9.3824e-03, -2.8279e-03,  2.0479e-02,  2.1873e-02, -2.5391e-02,\n",
       "           2.5088e-02, -3.8027e-03,  2.7618e-03,  1.9457e-02, -1.6252e-02,\n",
       "           2.0414e-02, -2.3053e-02, -2.5562e-02,  7.2214e-03,  6.4950e-03,\n",
       "          -3.4692e-02, -1.9120e-02, -2.5020e-02,  2.2383e-02,  3.5045e-02,\n",
       "           2.4982e-02, -6.6127e-03,  1.5583e-02, -1.8801e-02,  2.9141e-02,\n",
       "          -2.0814e-02,  2.2354e-02,  3.4492e-02,  2.9336e-03,  1.3932e-02,\n",
       "           2.6465e-02, -1.1166e-02, -1.7634e-02, -2.5532e-02, -2.2936e-02,\n",
       "          -1.5243e-02, -2.0634e-02,  1.8930e-02, -5.9333e-03,  2.1523e-02,\n",
       "           1.0232e-02,  2.6763e-02, -3.0701e-02,  3.4005e-02,  1.9318e-02,\n",
       "          -3.2993e-02,  1.4297e-02,  1.4674e-02,  3.3329e-02,  3.3678e-02,\n",
       "          -1.6019e-02, -2.8088e-02,  2.5877e-02,  3.3186e-02, -2.3772e-02,\n",
       "          -7.0388e-03,  2.8371e-02,  2.8094e-02, -2.0657e-03, -2.1135e-02,\n",
       "          -2.0908e-02, -3.3293e-02, -6.8017e-03,  1.0916e-02,  6.3099e-05,\n",
       "          -1.7112e-02,  1.6922e-02,  6.8755e-03, -2.0488e-02, -2.5374e-02,\n",
       "           6.3335e-03,  1.1230e-02,  3.2778e-02,  1.2653e-03, -3.0517e-02,\n",
       "          -7.7737e-03,  1.0795e-02,  8.4844e-03,  1.7792e-02,  3.4320e-02,\n",
       "           3.5268e-02,  3.3486e-02,  2.6679e-02, -4.7364e-03,  2.1997e-02,\n",
       "           2.5041e-02,  2.1634e-02, -2.1177e-02, -2.2853e-02, -7.5885e-03,\n",
       "          -8.9162e-04,  4.3575e-03,  2.3907e-02,  8.2863e-03, -2.5936e-03,\n",
       "          -1.2517e-02,  1.8415e-02,  3.1520e-02,  2.5357e-02, -5.9391e-03,\n",
       "           3.0089e-02, -9.5414e-03,  1.3179e-02, -2.1291e-02,  1.9903e-02,\n",
       "           2.9538e-02,  2.3137e-02,  1.0708e-02, -1.0648e-02,  1.7522e-02,\n",
       "           4.9071e-04,  3.1419e-02,  6.1362e-03,  4.3134e-03, -1.0017e-02,\n",
       "          -3.0152e-02,  2.6591e-02,  1.8202e-02,  4.7653e-03, -3.3490e-02,\n",
       "          -5.7735e-03, -1.4896e-02,  4.8516e-03, -2.4401e-02, -3.5445e-02,\n",
       "           1.4670e-02,  2.2602e-02,  2.0710e-03,  2.3300e-02,  2.7121e-02,\n",
       "          -1.5337e-02, -3.5153e-02, -3.3161e-02,  3.0165e-02,  5.7370e-03,\n",
       "           3.1890e-02, -1.1842e-02, -2.3094e-02,  2.9716e-02, -1.2119e-02,\n",
       "          -3.1263e-02, -1.7624e-03,  2.4959e-02,  2.8890e-02, -1.6539e-02,\n",
       "          -8.7057e-03,  2.2777e-02, -1.9682e-02,  1.3980e-02,  1.4670e-02,\n",
       "           1.6103e-02, -3.1119e-02, -8.1647e-03,  9.4398e-04, -2.7360e-02,\n",
       "           1.9016e-02, -9.9918e-03,  2.1205e-02, -1.9118e-02,  1.8698e-03,\n",
       "          -3.2829e-02,  3.0870e-02, -1.4346e-02, -5.9054e-03,  1.8159e-02,\n",
       "          -2.8854e-03, -1.6290e-02, -2.2099e-03, -2.4334e-02, -2.4938e-02,\n",
       "           1.8816e-02, -5.3596e-03, -1.0353e-03,  2.1375e-02,  3.5074e-02,\n",
       "          -2.1470e-02,  2.3756e-02,  5.7721e-03, -2.4222e-02,  3.7007e-04,\n",
       "          -2.5617e-03,  5.0366e-03, -2.1696e-02,  2.6930e-02, -2.8038e-02,\n",
       "          -3.2257e-02], requires_grad=True)),\n",
       " ('2.weight', <UninitializedParameter>),\n",
       " ('2.bias', <UninitializedParameter>)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param) for name, param in net.named_parameters()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f828b-8594-4233-9922-21076b179365",
   "metadata": {},
   "source": [
    "# Ex. 2 - O que acontece se você especificar dimensões incompatíveis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06c58131-8831-4b1b-9c02-4fd0b8c65194",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x256 and 64x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m net \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m784\u001b[39m,\u001b[38;5;241m256\u001b[39m),\n\u001b[0;32m      6\u001b[0m                     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m      7\u001b[0m                     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m10\u001b[39m)           \u001b[38;5;66;03m# Camada compatível seria:  nn.Linear(256,10) \u001b[39;00m\n\u001b[0;32m      8\u001b[0m                     )\n\u001b[0;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m784\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m                \u001b[38;5;66;03m# inicializando a primeira camada\u001b[39;00m\n",
      "File \u001b[1;32m~\\pythonProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\pythonProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\pythonProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\pythonProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\pythonProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\pythonProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x256 and 64x10)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(nn.Linear(784,256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64,10)           # Camada compatível seria:  nn.Linear(256,10) \n",
    "                    )\n",
    "\n",
    "X = torch.rand(2, 784)\n",
    "net(X)                # inicializando a primeira camada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba6eb8-76c8-4f16-aefd-c7b179ced4cc",
   "metadata": {},
   "source": [
    "Com dimensões incompatíveis a rede não funciona."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45cfac-355f-4401-b0be-655832a5ec4d",
   "metadata": {},
   "source": [
    "# Outras respostas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6429646-e085-4c32-935e-48a292b7fb35",
   "metadata": {},
   "source": [
    "https://pandalab.me/archives/lazy_initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09141e8-7cc8-4b8e-9efa-bab471f18e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
