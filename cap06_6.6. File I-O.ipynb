{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bca629-0fcd-48ee-ba48-5cafd1a9663c",
   "metadata": {},
   "source": [
    "# 6.6. File I/O\n",
    "\n",
    "Vide exercício 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca616bca-93bb-4887-bf4e-23341fa3fede",
   "metadata": {},
   "source": [
    "Até agora, discutimos como processar dados e como construir, treinar e testar modelos de aprendizado profundo. No entanto, em algum momento, esperamos estar felizes o suficiente com os modelos aprendidos que desejaremos salvar os resultados (finais ou parciais (checkpointing)) para uso posterior em vários contextos.\n",
    "\n",
    "Portanto, é hora de aprender como carregar e armazenar vetores de peso individuais e modelos inteiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0204a9b-13e4-4922-a242-4a6db994f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn                        # para usar nn. ao invés de torch.nn\n",
    "from torch.nn import functional as F        # para usar F. ao invés de torch.nn.functional\n",
    "\n",
    "# https://pytorch.org/docs/stable/nn.functional.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477ec2e-1248-435b-a858-7673312cfd4f",
   "metadata": {},
   "source": [
    "# 6.6.1. Loading and Saving Tensors\n",
    "\n",
    "- Loading: torch.load\n",
    "- Saving:  torch.save\n",
    "\n",
    "\n",
    "Para tensores individuais, podemos invocar diretamente as funções __load__ e __save__ para lê-los e escrevê-los, respectivamente. Ambas as funções exigem que forneçamos um nome e save exigem como entrada a variável a ser salva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c1f755d-c0d6-4d8f-ae73-886da65018c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')   # x foi salvo na pasta raiz com o nome 'x-file'\n",
    "\n",
    "# Pasta raiz: \n",
    "# G:\\Meu Drive\\0-DOUTORADO\\0-Python\\PycharmProjects\\Deep_Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a3d07-001a-4879-b37e-c14c7d350734",
   "metadata": {},
   "source": [
    "Agora podemos ler os dados do arquivo armazenado de volta na memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc483497-36e6-45ec-850c-8baafb14546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558284b-804b-44b6-9e34-c770e9b420be",
   "metadata": {},
   "source": [
    "Podemos armazenar uma lista de tensores e lê-los de volta na memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc923693-ae28-4198-955a-7aaeedc36b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)                # tensor y: tensor([0., 0., 0., 0.])\n",
    "torch.save([x, y],'x-files')      # salva lista de tensores: [x,y]\n",
    "x2, y2 = torch.load('x-files')    # carrega tensores salvos. x2 será igual ao elemento [0] e y2 será igual ao elemento [1].\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efa5d91e-8d11-43ae-9c2b-b1c5c624be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8dc6c9-fc0c-4dcb-9abb-e81c85bd5b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667c0d50-40ef-42fb-836b-2648d88c6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('x-files')        # Neste caso a lista inteira é carregada na variável a. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31b63ecb-105f-45a3-bec2-928c1d424d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dc45b-1048-4d4a-9004-505f6600d445",
   "metadata": {},
   "source": [
    "Podemos até escrever e ler um dicionário que mapeia de strings para tensores. Isso é conveniente quando queremos ler ou escrever todos os pesos em um modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "100b5c66-4691-44f4-989d-f8476b277cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {'x': x, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50c9b0b0-4267-435f-be88-fee47536914a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93a17ae3-0cf1-48e6-becd-8adc3b1ac7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f76b9-9ffb-4d22-81b0-30800b8f33d9",
   "metadata": {},
   "source": [
    "# 6.6.2. Loading and Saving Model Parameters\n",
    "\n",
    "A estrutura de aprendizado profundo fornece funcionalidades integradas para carregar e salvar redes inteiras.\n",
    "\n",
    "Um detalhe importante a ser observado é que isso salva parâmetros do modelo e não o modelo inteiro. \n",
    "\n",
    "Vamos começar com nosso MLP familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5f1d27e2-178f-4a5b-b1dd-dfe884965640",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.output = nn.LazyLinear(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d9bfa158-8345-4316-bd13-723ac064e89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7d569fed-3883-4b50-813f-5b6b44eb57eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a960eb8-66b2-4855-824b-6edfeb3168b0",
   "metadata": {},
   "source": [
    "Em seguida, armazenamos os parâmetros do modelo como um arquivo com o nome “mlp.params”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6ab3a1fd-0545-429b-83ee-eace11066c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# armazenamos os parâmetros do modelo como um arquivo com o nome “mlp.params”\n",
    "torch.save(net.state_dict(), 'mlp.params')         #  EXTENSÃO PARA PARÂMETROS: .params           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "df87cf60-1cdb-4a43-b3d5-b815901aea0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.1637, -0.2161,  0.0046,  ...,  0.0528, -0.0274,  0.1120],\n",
       "                      [ 0.0064,  0.1223,  0.0137,  ...,  0.0890,  0.0146, -0.0184],\n",
       "                      [-0.1966,  0.0962,  0.0600,  ..., -0.1850, -0.0472, -0.2086],\n",
       "                      ...,\n",
       "                      [ 0.2130,  0.1504,  0.0305,  ..., -0.0195,  0.1584,  0.1350],\n",
       "                      [-0.1411, -0.0099, -0.0943,  ..., -0.1738,  0.2106,  0.0988],\n",
       "                      [ 0.2201,  0.0375,  0.0749,  ..., -0.1360,  0.1319, -0.0959]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([ 0.2097, -0.1271,  0.0918, -0.0254, -0.0600, -0.0233, -0.0498, -0.1440,\n",
       "                      -0.0146,  0.0687,  0.2167, -0.1991,  0.0698,  0.1813,  0.0134,  0.0491,\n",
       "                       0.0433, -0.1657, -0.0784,  0.0357, -0.2121,  0.1998,  0.1318, -0.0928,\n",
       "                       0.0950, -0.1568,  0.0545, -0.2223,  0.1367,  0.0169,  0.1443,  0.0868,\n",
       "                       0.1441, -0.1595,  0.1346,  0.1813, -0.1076, -0.0754, -0.1560, -0.0371,\n",
       "                       0.0528,  0.0182, -0.1272,  0.0558, -0.1013, -0.0890, -0.0625,  0.0918,\n",
       "                      -0.0852,  0.1430, -0.0718, -0.1307, -0.1719,  0.1086, -0.0841, -0.2011,\n",
       "                       0.0487, -0.0440,  0.0048,  0.0604,  0.1792, -0.1970,  0.2063, -0.1419,\n",
       "                      -0.1979,  0.1894, -0.1261,  0.1638, -0.0179,  0.1455, -0.0427,  0.0303,\n",
       "                      -0.2221,  0.1167,  0.0308, -0.1782,  0.2137, -0.0434,  0.1866,  0.1359,\n",
       "                       0.1950,  0.1584, -0.1504, -0.0965, -0.0730,  0.2141,  0.0834,  0.0503,\n",
       "                       0.1672, -0.0775,  0.2135,  0.1611, -0.1169,  0.0079,  0.2171, -0.0983,\n",
       "                       0.1418,  0.0642, -0.1296,  0.0609,  0.1475, -0.0284,  0.0985, -0.2070,\n",
       "                      -0.1148,  0.1568, -0.0646, -0.1960,  0.1298, -0.0381,  0.1546, -0.0744,\n",
       "                      -0.0069,  0.0099,  0.0608,  0.1096,  0.0506, -0.0552, -0.0088,  0.0919,\n",
       "                      -0.2045, -0.1836,  0.1348, -0.1105, -0.1461,  0.2064,  0.1224, -0.1344,\n",
       "                      -0.0236,  0.2093, -0.1778,  0.1819, -0.0970, -0.0526, -0.2207, -0.0559,\n",
       "                      -0.0216, -0.1490, -0.1103,  0.0170,  0.0076,  0.0406, -0.2139,  0.1126,\n",
       "                      -0.0053, -0.0742, -0.0531, -0.1086,  0.1017,  0.0804,  0.1168,  0.1374,\n",
       "                       0.0604,  0.1667,  0.0227, -0.1531, -0.2048,  0.0778,  0.1139, -0.1288,\n",
       "                       0.2193,  0.2162,  0.0386,  0.0046,  0.1668, -0.0242, -0.1043, -0.0679,\n",
       "                      -0.1689,  0.1157,  0.1528, -0.0058, -0.1094, -0.2156,  0.0124,  0.1421,\n",
       "                       0.0860,  0.0891,  0.0580, -0.0151, -0.1139,  0.0334, -0.0964, -0.0013,\n",
       "                      -0.2110, -0.0073, -0.0554,  0.1230, -0.0852,  0.0885, -0.0311,  0.0330,\n",
       "                      -0.0460,  0.1344,  0.0052,  0.0349, -0.0348,  0.1588, -0.0615,  0.0479,\n",
       "                      -0.1037, -0.1652,  0.0587, -0.1465, -0.1978,  0.0274, -0.1247,  0.2030,\n",
       "                       0.1274,  0.1077, -0.0566, -0.0760, -0.0441, -0.0404, -0.0789,  0.1368,\n",
       "                      -0.1030, -0.1151, -0.1651, -0.1223, -0.0780,  0.0594,  0.0200, -0.1870,\n",
       "                      -0.0739,  0.2069,  0.1840,  0.0970,  0.0589, -0.0082, -0.0332,  0.1612,\n",
       "                      -0.0041,  0.0364, -0.1954, -0.0740, -0.1776, -0.1056,  0.2236, -0.0056,\n",
       "                       0.1294,  0.0430,  0.1709, -0.1869,  0.0738, -0.0353, -0.1510, -0.2188,\n",
       "                      -0.0971, -0.0921,  0.1354, -0.1917,  0.1076, -0.2130,  0.0265, -0.0004])),\n",
       "             ('output.weight',\n",
       "              tensor([[ 0.0182,  0.0598, -0.0036,  ...,  0.0156, -0.0031,  0.0363],\n",
       "                      [ 0.0029,  0.0411, -0.0582,  ...,  0.0306, -0.0505,  0.0169],\n",
       "                      [-0.0550,  0.0090,  0.0378,  ..., -0.0267,  0.0523, -0.0362],\n",
       "                      ...,\n",
       "                      [-0.0239,  0.0011,  0.0318,  ...,  0.0244,  0.0263,  0.0258],\n",
       "                      [ 0.0490, -0.0045, -0.0154,  ...,  0.0209, -0.0250,  0.0108],\n",
       "                      [ 0.0550, -0.0550, -0.0382,  ...,  0.0399, -0.0285,  0.0289]])),\n",
       "             ('output.bias',\n",
       "              tensor([ 6.0243e-02, -7.5446e-03,  3.1211e-02,  3.4317e-05, -1.5372e-02,\n",
       "                       4.1830e-02,  1.4184e-02, -1.8602e-02, -3.0017e-02,  1.4323e-02]))])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parâmetros:\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "253c54e7-46a6-46f3-9477-c235dc9ca479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hidden.weight', torch.Size([256, 20])),\n",
       " ('hidden.bias', torch.Size([256])),\n",
       " ('output.weight', torch.Size([10, 256])),\n",
       " ('output.bias', torch.Size([10]))]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nome e shape dos parâmetros:\n",
    "[(name, param.shape) for name, param in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e7ae5-f0c2-4871-815e-f9ce40c4ce9e",
   "metadata": {},
   "source": [
    "Para recuperar o modelo, instanciamos um clone do modelo MLP original. Em vez de inicializar aleatoriamente os parâmetros do modelo, lemos os parâmetros armazenados no arquivo diretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4fef1e83-5bf4-4582-99dc-c710be00efc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()                                      #  clone do modelo MLP original.      \n",
    "clone.load_state_dict(torch.load('mlp.params'))    # carrega os dados salvos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "67965e7b-7d33-42f7-a292-9caf281b65f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc75d8-31c4-49ab-8b58-0dd5f432d094",
   "metadata": {},
   "source": [
    "Como ambas as instâncias têm os mesmos parâmetros de modelo, o resultado computacional para a mesma entrada X deve ser o mesmo. Vamos verificar isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "87e90071-7870-4ee1-a2cd-0818747f87d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b8f1f2e2-ffcb-48e8-85f7-e6a8353723d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0712,  0.1360,  0.5060, -0.0326,  0.3252,  0.4594, -0.0410,  0.6288,\n",
       "          0.2902, -0.0191],\n",
       "        [-0.0205,  0.0549,  0.0193,  0.1864,  0.2478,  0.1678,  0.0109,  0.1173,\n",
       "          0.0301, -0.2687]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)                        # Saída Y utilizando como entrada X\n",
    "Y_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4e29c4c2-02e2-4e42-a1b6-7af51c4e4ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e2d56646-def2-4115-9368-1aa8ebf4e6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hidden.weight', torch.Size([256, 20])),\n",
       " ('hidden.bias', torch.Size([256])),\n",
       " ('output.weight', torch.Size([10, 256])),\n",
       " ('output.bias', torch.Size([10]))]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param.shape) for name, param in clone.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cfe5c7f8-5dee-47ad-80dc-9796d420c668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone.state_dict()['hidden.weight'] == net.state_dict()['hidden.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "100885dd-bc0a-4f29-9f82-3c730c2e56a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone.state_dict()['hidden.bias'] == net.state_dict()['hidden.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e73cf2f7-217c-43fc-950d-cfe14500948a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone.state_dict()['output.weight'] == net.state_dict()['output.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "15fa5ce4-8b4e-4ebf-94c8-f4c4f21e858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone.state_dict()['output.bias'] == net.state_dict()['output.bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35339335-2612-4f87-ac57-db1bae578eab",
   "metadata": {},
   "source": [
    "# 6.6.3. Resumo\n",
    "\n",
    "- As funções save e load podem ser usadas para executar E/S de arquivo para objetos tensor. \n",
    "\n",
    "- Podemos salvar e carregar todos os conjuntos de parâmetros para uma rede por meio de um dicionário de parâmetros. \n",
    "\n",
    "- Salvar a arquitetura tem que ser feito em código, em vez de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "24871830-84bf-428d-ac2d-1bb435e90cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE:\n",
    "torch.save(net.state_dict(), 'mlp.params')   # salva todos os parâmetros do modelo.\n",
    " #  EXTENSÃO PARA PARÂMETROS: .params   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "854e61d7-e019-4d03-a3ef-7bb911b32766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD:\n",
    "# Recuperar/carregar os parâmetros salvos.\n",
    "clone = MLP()                                    # instanciamos um clone do modelo MLP original\n",
    "clone.load_state_dict(torch.load('mlp.params'))  # lemos os parâmetros armazenados no arquivo diretamente.\n",
    "clone.eval()\n",
    " #  EXTENSÃO PARA PARÂMETROS: .params   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbcd3ba1-e925-47b3-88b6-cc00ec79be37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e18a9-f847-491a-8275-8086cd50e630",
   "metadata": {},
   "source": [
    "# 6.6.4. Exercícios\n",
    "\n",
    "# Ex.1 - Mesmo que não haja necessidade de implantar modelos treinados em um dispositivo diferente, quais são os benefícios práticos de armazenar parâmetros de modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dba525-34d4-462b-be4d-6fe89521c25c",
   "metadata": {},
   "source": [
    "- Economia de tempo e recursos, utilizando parâmetros já direcionados/sintonizados (tuning) em uma direção correta.\n",
    "- Evita retreinamento do modelo toda vez que for utilizá-lo.\n",
    "- Criação de versão de modelos.\n",
    "- Tranferência de parâmetros / Transferência de conhecimentos / Compartilhamento e Colaboração."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455e6c2-cb95-48fd-8387-a05baad8af50",
   "metadata": {},
   "source": [
    "# Ex.2 - Suponha que queremos reutilizar apenas partes de uma rede para serem incorporadas a uma rede com uma arquitetura diferente. Como você faria para usar, digamos, as duas primeiras camadas de uma rede anterior em uma nova rede?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d130564-7dee-41c4-918b-f427e57925fb",
   "metadata": {},
   "source": [
    "PARTE 1: CRIAÇÃO E ANÁLISE DA REDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5d30d246-049e-43c2-8bb0-d15e97de2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "933b5fd6-8900-4c02-8b03-043262d716a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSE PARA REDE SEM ENTRADAS (LazyLinear)\n",
    "class MLP(d2l.Classifier):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.LazyLinear(50),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.LazyLinear(20),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.LazyLinear(2)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0378c77f-4c6a-42e5-b827-177de4099b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP()       # Rede sem entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "83faff34-c7f5-45d1-834a-c2fe34bc6e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LazyLinear(in_features=0, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): LazyLinear(in_features=0, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net               # Observe: LazyLinear(in_features=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "27f0ddfe-22a0-415f-8bfb-bb09ad4df307",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(size=(10, 100))    # Dados de entrada X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f299bf01-8cef-46f2-9c64-a6614f792041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1661, -0.1892],\n",
       "        [ 0.1658, -0.2083],\n",
       "        [ 0.1912, -0.1713],\n",
       "        [ 0.1990, -0.2247],\n",
       "        [ 0.1873, -0.1955],\n",
       "        [ 0.1901, -0.1793],\n",
       "        [ 0.1880, -0.1796],\n",
       "        [ 0.1754, -0.1882],\n",
       "        [ 0.1913, -0.2157],\n",
       "        [ 0.1692, -0.2003]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(X)                        # Saída Y utilizando como entrada X\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f5b687fc-9c4e-4057-a269-04d57ede33ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=20, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net                            # Observe: Linear(in_features=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e608c1-541d-405c-863c-8b87e829b5e3",
   "metadata": {},
   "source": [
    "- Observe que agora net alterou-se de LazyLinear para Linear.\n",
    "- Antes: in_features=0\n",
    "- Agora: in_features=100\n",
    "\n",
    "Logo, a entrada X foi aplicada.\n",
    "\n",
    "net é uma rede com 5 camadas: 0 a 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3cd80113-0e62-4af6-9671-a03b2f929920",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "34f3ab4b-80d8-4998-b847-390e3649896d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LazyLinear(in_features=0, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): LazyLinear(in_features=0, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ca4e020c-5975-476a-a46b-8b35e086b29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LazyLinear(in_features=0, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): LazyLinear(in_features=0, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "af341f85-46c1-4097-9e86-9c3c540e30e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LazyLinear(in_features=0, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acessando apenas parte da rede:\n",
    "reused_layer = clone.net[:2]\n",
    "reused_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e485b-917e-48bd-9044-6f6c8ea6a4d6",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d8f3d-7166-40eb-a451-259d34e06826",
   "metadata": {},
   "source": [
    "# PARTE 2: SALVANDO AS DUAS PRIMEIRAS CAMADAS (0) E (2):\n",
    "\n",
    "Para isto será utilizado o OrderedDict, pois está no mesmo formato de net.state_dict().\n",
    "\n",
    "type(net.state_dict())  \\\n",
    "out: collections.OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9618c088-eb0f-45cb-8e2e-31f8588b243b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('net.0.weight', torch.Size([50, 100])),\n",
       " ('net.0.bias', torch.Size([50])),\n",
       " ('net.2.weight', torch.Size([20, 50])),\n",
       " ('net.2.bias', torch.Size([20])),\n",
       " ('net.4.weight', torch.Size([2, 20])),\n",
       " ('net.4.bias', torch.Size([2]))]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VISUALIZANDO AS CAMADAS:\n",
    "[(name, param.shape) for name, param in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "838dd197-0739-49b4-8399-39aa48fd7f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(net.state_dict())     # .state_dict() é um OrderedDict:6\n",
    "\n",
    "# Its API is essentially the same as dict . However, OrderedDict iterates over keys and values in the same order that the keys were inserted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fde4c51b-13fd-426e-9b87-50cc50b3647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), 'mlp.params')   # salva todos os parâmetros do modelo.\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# OrderedDict:\n",
    "camadas = OrderedDict([\n",
    "    ('net.0.weight' ,net.state_dict()['net.0.weight']),\n",
    "    ('net.0.bias' ,net.state_dict()['net.0.bias']),\n",
    "    ('net.2.weight' ,net.state_dict()['net.2.weight']),\n",
    "    ('net.2.bias' ,net.state_dict()['net.2.bias'])             ])\n",
    "# camadas é um OrderedDict:4\n",
    "\n",
    "torch.save(camadas, 'mlp.params')                                     # salva camadas\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6e3f5-3111-490d-81e6-7aadbb2b3c6a",
   "metadata": {},
   "source": [
    "LOAD:  \\\n",
    "Recuperar/carregar os parâmetros salvos.  \\\n",
    "O código abaixo apresenta erro pois ``camadas`` possui apenas 4 dos 6 parâmetros. Logo, é preciso adicionar os parâmetros restantes. \n",
    "\n",
    "clone = MLP()                                    # instanciamos um clone do modelo MLP original  \\\n",
    "clone.load_state_dict(torch.load('mlp.params'))  # lemos os parâmetros armazenados no arquivo diretamente.  \\\n",
    "clone.eval()  \n",
    "\n",
    "_RuntimeError: Error(s) in loading state_dict for MLP:_  \\\n",
    "_Missing key(s) in state_dict: \"net.4.weight\", \"net.4.bias\"._ \n",
    "\n",
    "Faltam:\n",
    "'net.4.weight', \n",
    "'net.4.bias'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9e8fcb46-9661-46c2-9615-72f5dc84174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECLARANDO OS PARÂMETROS FALTANTES E INCORPORANDO-OS AO OrderedDict CAMADAS:\n",
    "\n",
    " # ('net.4.weight', torch.Size([2, 20])),\n",
    " # ('net.4.bias', torch.Size([2]))]\n",
    "\n",
    "camadas['net.4.weight']  = torch.randn(2, 20) \n",
    "camadas['net.4.bias']    = torch.randn(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ceadaef7-5c7b-4612-8f97-586e864aadfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weight',\n",
       "              tensor([[ 0.0719,  0.0439,  0.0277,  ...,  0.0840, -0.0769,  0.0545],\n",
       "                      [ 0.0731, -0.0967, -0.0125,  ..., -0.0629,  0.0282,  0.0599],\n",
       "                      [ 0.0411, -0.0464,  0.0003,  ..., -0.0458, -0.0645, -0.0345],\n",
       "                      ...,\n",
       "                      [-0.0678, -0.0042, -0.0967,  ...,  0.0188,  0.0742, -0.0594],\n",
       "                      [ 0.0163,  0.0156,  0.0225,  ..., -0.0875, -0.0565,  0.0687],\n",
       "                      [ 0.0847, -0.0123,  0.0827,  ..., -0.0834,  0.0106,  0.0904]])),\n",
       "             ('net.0.bias',\n",
       "              tensor([-0.0533, -0.0312, -0.0219,  0.0977,  0.0210,  0.0183,  0.0334, -0.0884,\n",
       "                      -0.0443, -0.0231, -0.0813,  0.0199, -0.0857,  0.0860, -0.0488, -0.0392,\n",
       "                       0.0963, -0.0159, -0.0127, -0.0698,  0.0716,  0.0124, -0.0793,  0.0905,\n",
       "                      -0.0093, -0.0768,  0.0497,  0.0229, -0.0832,  0.0245,  0.0223,  0.0136,\n",
       "                       0.0872, -0.0940, -0.0041,  0.0941, -0.0550, -0.0629, -0.0186, -0.0326,\n",
       "                       0.0484, -0.0208, -0.0343,  0.0159,  0.0675,  0.0048,  0.0989, -0.0945,\n",
       "                      -0.0396,  0.0685])),\n",
       "             ('net.2.weight',\n",
       "              tensor([[ 0.0031, -0.1128,  0.1257,  0.0766, -0.0884,  0.0382, -0.1209,  0.0779,\n",
       "                        0.1165, -0.1319, -0.0219,  0.0756,  0.0816,  0.0894, -0.0957, -0.1134,\n",
       "                       -0.1295, -0.0256, -0.0350,  0.0106,  0.0491, -0.0450, -0.0140,  0.0186,\n",
       "                       -0.0865,  0.0248,  0.0930,  0.0438,  0.1261,  0.1133,  0.0718,  0.0268,\n",
       "                       -0.1273, -0.1377, -0.0456,  0.0623, -0.1324, -0.0038, -0.0144,  0.1392,\n",
       "                       -0.0949, -0.0765, -0.0628, -0.1397, -0.1185, -0.0626,  0.1342, -0.0707,\n",
       "                       -0.0259,  0.0511],\n",
       "                      [ 0.1381, -0.1052,  0.1164,  0.0673, -0.0409,  0.0430,  0.0857,  0.0644,\n",
       "                       -0.1140, -0.0699, -0.0720, -0.0122, -0.0822,  0.0938,  0.0111,  0.1318,\n",
       "                        0.0605, -0.0086, -0.0016, -0.0914, -0.0050,  0.1033, -0.0603,  0.0875,\n",
       "                       -0.0456, -0.1076, -0.0122, -0.0143, -0.0212,  0.0960, -0.0141,  0.0152,\n",
       "                        0.1290, -0.0790,  0.0690,  0.1176, -0.1347,  0.0893, -0.0892,  0.0510,\n",
       "                       -0.0948, -0.0832, -0.0689,  0.0798, -0.1110,  0.0968, -0.0382,  0.1319,\n",
       "                       -0.0694,  0.0044],\n",
       "                      [-0.0585, -0.0634, -0.0913, -0.0592, -0.0786,  0.0027,  0.0725, -0.0352,\n",
       "                       -0.0144,  0.0573, -0.0542, -0.0614,  0.1036, -0.1410,  0.1381,  0.1071,\n",
       "                       -0.1157,  0.0597,  0.1082, -0.0610,  0.1125, -0.0473,  0.0065, -0.0075,\n",
       "                        0.1278,  0.0979,  0.0717, -0.0644, -0.0177,  0.0832, -0.0616, -0.1235,\n",
       "                       -0.0995,  0.0347, -0.0982, -0.0516,  0.0475, -0.0192,  0.1068, -0.1045,\n",
       "                       -0.0571, -0.0176, -0.0113, -0.0855,  0.1377,  0.0739, -0.0569,  0.0353,\n",
       "                        0.1328, -0.0086],\n",
       "                      [-0.0837, -0.1027, -0.0105, -0.0225, -0.0206, -0.0778,  0.1234,  0.0868,\n",
       "                        0.1332,  0.0565, -0.0623, -0.0863,  0.0475,  0.0190, -0.1379, -0.0322,\n",
       "                        0.0388, -0.0317,  0.1339, -0.0240,  0.0337,  0.0760,  0.0167,  0.0296,\n",
       "                        0.0196,  0.0849, -0.0380,  0.0548,  0.0536,  0.0613,  0.1058, -0.0171,\n",
       "                        0.0676,  0.0421,  0.0846,  0.0274,  0.0546, -0.0910,  0.0657, -0.1002,\n",
       "                        0.0734, -0.0205,  0.0532,  0.0485,  0.0661, -0.1149, -0.1395, -0.0231,\n",
       "                       -0.0350,  0.0593],\n",
       "                      [-0.0340,  0.0946,  0.0514, -0.0309,  0.0667,  0.0310,  0.1195, -0.0750,\n",
       "                       -0.0724, -0.0407,  0.1410,  0.0535, -0.1063,  0.0684,  0.1381,  0.0892,\n",
       "                        0.0252,  0.0879, -0.1088,  0.0008, -0.0901,  0.0115,  0.1280, -0.1067,\n",
       "                       -0.1236,  0.0924,  0.0327, -0.0715, -0.0794, -0.1329,  0.0593, -0.0865,\n",
       "                        0.0659, -0.0976,  0.0158, -0.0418,  0.0445, -0.1264,  0.0117,  0.1321,\n",
       "                        0.0314,  0.1362, -0.1176, -0.1049, -0.1350,  0.0550,  0.1187, -0.0150,\n",
       "                        0.0716, -0.1203],\n",
       "                      [ 0.1171,  0.1357, -0.0222,  0.0662,  0.0398, -0.1067,  0.1333, -0.0991,\n",
       "                        0.1114,  0.0879,  0.0392,  0.0201, -0.0531,  0.0163, -0.0609,  0.0412,\n",
       "                       -0.1093, -0.1353,  0.1348,  0.1324,  0.0045, -0.0575, -0.1035, -0.0905,\n",
       "                       -0.0347,  0.0582, -0.0810,  0.0482, -0.0934,  0.1132,  0.0962,  0.0801,\n",
       "                       -0.0485,  0.1157,  0.1238,  0.1391,  0.0852, -0.0860, -0.0361, -0.0670,\n",
       "                        0.1165, -0.0287, -0.0534,  0.0753, -0.1316, -0.0082,  0.0858, -0.0983,\n",
       "                        0.1092, -0.0625],\n",
       "                      [ 0.1323, -0.0761, -0.1193, -0.0537,  0.0577,  0.0958,  0.1265, -0.1359,\n",
       "                       -0.0239, -0.1105,  0.0567,  0.1233, -0.0956, -0.0986, -0.0775,  0.0141,\n",
       "                        0.0475, -0.1103,  0.0354,  0.0757, -0.0296,  0.0303, -0.0933, -0.0314,\n",
       "                        0.0644,  0.0941,  0.0220,  0.1085, -0.1204,  0.0709, -0.1357,  0.0790,\n",
       "                       -0.0822,  0.0451,  0.1125,  0.0270, -0.1225,  0.0046,  0.0827, -0.1014,\n",
       "                        0.0636,  0.0913, -0.0594,  0.0352, -0.1143,  0.1120, -0.1207, -0.1062,\n",
       "                       -0.0825, -0.0991],\n",
       "                      [ 0.0708,  0.0902, -0.0163, -0.1264,  0.1214,  0.0586, -0.0901,  0.0652,\n",
       "                        0.0907, -0.1223, -0.0903, -0.0143, -0.1204, -0.0067, -0.1110, -0.1174,\n",
       "                       -0.0962,  0.0913, -0.1046,  0.1153,  0.0281,  0.1227, -0.0883, -0.0228,\n",
       "                       -0.0427,  0.0395,  0.0286, -0.1150,  0.0827,  0.0962,  0.0248, -0.0323,\n",
       "                        0.0318,  0.1383, -0.1389, -0.0144, -0.1315,  0.0040,  0.1144,  0.0717,\n",
       "                       -0.0605, -0.1120, -0.0412, -0.1180, -0.0084,  0.0981,  0.0339, -0.1047,\n",
       "                       -0.0502, -0.1289],\n",
       "                      [-0.1011, -0.1412, -0.0539,  0.0405,  0.0604,  0.1347,  0.0285, -0.1059,\n",
       "                       -0.0861,  0.1070,  0.0673, -0.0995, -0.0488, -0.0912, -0.0005,  0.0219,\n",
       "                        0.0020,  0.0036, -0.0564, -0.0444,  0.0244, -0.0894, -0.0087,  0.1035,\n",
       "                       -0.0442, -0.0873,  0.0082, -0.0460,  0.0701, -0.0352,  0.1009,  0.1198,\n",
       "                       -0.1226,  0.0174,  0.1325,  0.0080,  0.1379, -0.0204, -0.0772,  0.0138,\n",
       "                        0.0088, -0.0563,  0.0910, -0.0736,  0.0767, -0.1144,  0.1409,  0.0955,\n",
       "                        0.1298,  0.0018],\n",
       "                      [-0.0742, -0.0584, -0.1207, -0.0458, -0.0899, -0.0652, -0.1171, -0.1174,\n",
       "                        0.0734, -0.0919, -0.1161,  0.1364, -0.0287, -0.0619,  0.1296,  0.0559,\n",
       "                       -0.0856, -0.0496, -0.1196, -0.0468, -0.0622, -0.1187, -0.1131, -0.0642,\n",
       "                        0.0557, -0.0795,  0.0337,  0.0624, -0.1186, -0.0507, -0.0542, -0.0118,\n",
       "                       -0.0002,  0.1029,  0.0652,  0.1143,  0.0712,  0.0892, -0.0181,  0.0758,\n",
       "                       -0.0559, -0.0614, -0.0736,  0.1017,  0.0979,  0.1250,  0.0802, -0.0965,\n",
       "                       -0.0742,  0.1235],\n",
       "                      [ 0.1284, -0.0853, -0.0968, -0.0791, -0.1228, -0.0200, -0.0893,  0.0529,\n",
       "                        0.0022,  0.0498,  0.1016, -0.1313,  0.0850, -0.0541, -0.0366,  0.1246,\n",
       "                        0.0468, -0.0516, -0.0492,  0.0562, -0.1395,  0.0241,  0.1070, -0.1350,\n",
       "                        0.0784, -0.1108,  0.0398,  0.0289,  0.0453, -0.1109, -0.0437,  0.0127,\n",
       "                       -0.1247,  0.0465, -0.0180, -0.0449,  0.0120,  0.0134, -0.0264, -0.0736,\n",
       "                        0.0390, -0.0620,  0.0239,  0.1196,  0.0048,  0.0446, -0.0643, -0.0959,\n",
       "                       -0.0342,  0.0845],\n",
       "                      [-0.0940, -0.0764,  0.0744, -0.1335,  0.0669,  0.0669,  0.1320,  0.0903,\n",
       "                       -0.0997,  0.0060, -0.1074,  0.0117,  0.1285,  0.1119, -0.0012,  0.0319,\n",
       "                        0.0660,  0.0099,  0.1124, -0.0862, -0.0063,  0.0965, -0.0131,  0.0445,\n",
       "                       -0.1322, -0.0754,  0.0977, -0.0147,  0.0703, -0.1356, -0.0644, -0.1394,\n",
       "                        0.0060, -0.0912,  0.0126,  0.0110, -0.1356,  0.0522,  0.0382, -0.1120,\n",
       "                       -0.0316,  0.0988, -0.0957,  0.0375,  0.1260, -0.0734, -0.0422, -0.1321,\n",
       "                       -0.0413,  0.1074],\n",
       "                      [ 0.0088, -0.0597,  0.0873,  0.0529, -0.1336, -0.1126, -0.0512,  0.0923,\n",
       "                       -0.0852, -0.0932,  0.0003, -0.0084, -0.0387,  0.0061, -0.1320, -0.1385,\n",
       "                        0.1123,  0.1230, -0.1238,  0.0502,  0.0469,  0.0178,  0.0726, -0.0481,\n",
       "                       -0.0424, -0.1319, -0.0754, -0.0277, -0.1306,  0.0126,  0.0011,  0.0924,\n",
       "                       -0.0098,  0.0225,  0.0970, -0.0498,  0.0717,  0.0933, -0.0738,  0.0328,\n",
       "                       -0.0274, -0.0875, -0.0156, -0.1238,  0.1355, -0.0549,  0.0644,  0.0647,\n",
       "                       -0.0552, -0.0945],\n",
       "                      [ 0.0563, -0.0136,  0.0206,  0.0803,  0.0216, -0.0704, -0.0341, -0.0734,\n",
       "                       -0.0534,  0.0676,  0.0887,  0.1195, -0.0018,  0.0364,  0.0184, -0.0331,\n",
       "                       -0.1204,  0.0558, -0.0986,  0.0401,  0.0155,  0.1344, -0.0847,  0.1296,\n",
       "                       -0.0542, -0.0904,  0.1346, -0.0772, -0.1002,  0.1290,  0.0665,  0.0675,\n",
       "                        0.1370, -0.0287,  0.0319,  0.1102, -0.1001, -0.0890, -0.0200,  0.0284,\n",
       "                        0.0074, -0.0260,  0.1229,  0.0213, -0.0271,  0.0740,  0.1413, -0.1237,\n",
       "                       -0.0333, -0.0371],\n",
       "                      [-0.0758, -0.0122,  0.1102,  0.1390,  0.1327,  0.0433, -0.0127, -0.0518,\n",
       "                        0.0997, -0.1114, -0.0490,  0.0540, -0.1034,  0.1220, -0.1128, -0.0115,\n",
       "                        0.0127,  0.0111,  0.0757,  0.0589, -0.0432,  0.1051,  0.1184, -0.0934,\n",
       "                       -0.1177, -0.0113, -0.0615, -0.0137,  0.0293,  0.0644,  0.0924,  0.0279,\n",
       "                        0.0722, -0.1013,  0.0753,  0.0304,  0.0506, -0.0921,  0.1084, -0.0649,\n",
       "                        0.0477,  0.1211, -0.1123, -0.0804,  0.0909, -0.0328,  0.0473, -0.0267,\n",
       "                       -0.0956, -0.0457],\n",
       "                      [ 0.1395, -0.0722,  0.0202, -0.0671,  0.0491, -0.0928, -0.1269, -0.0972,\n",
       "                       -0.0056,  0.0605,  0.0011, -0.1083, -0.1161, -0.0030,  0.0244, -0.0761,\n",
       "                        0.1009,  0.1344,  0.0843, -0.1158,  0.0460,  0.0299,  0.0812,  0.0221,\n",
       "                        0.1261, -0.0841, -0.0730, -0.0683,  0.0126, -0.0527, -0.0537, -0.1252,\n",
       "                       -0.0036, -0.0746, -0.1090, -0.0439, -0.0952, -0.1204, -0.0701, -0.1353,\n",
       "                        0.0923, -0.0217,  0.0352, -0.1060,  0.1193, -0.0892,  0.0691,  0.0817,\n",
       "                        0.0785,  0.0696],\n",
       "                      [-0.1251, -0.0111, -0.0304, -0.0366,  0.1244,  0.0965,  0.1309,  0.1409,\n",
       "                       -0.1127,  0.0325, -0.1074,  0.0639,  0.0082,  0.1050, -0.0676, -0.1244,\n",
       "                        0.0410,  0.1274, -0.1298,  0.0409, -0.0068,  0.1409, -0.1104, -0.0726,\n",
       "                        0.0717,  0.0908, -0.1134,  0.1067,  0.0646, -0.1058,  0.0128, -0.1402,\n",
       "                        0.0213,  0.1305, -0.0481, -0.0925, -0.1032, -0.0297, -0.0086, -0.0758,\n",
       "                       -0.0294, -0.0805, -0.0704, -0.1202,  0.0609, -0.1088,  0.0634, -0.0333,\n",
       "                       -0.0094, -0.0793],\n",
       "                      [-0.0930, -0.1353,  0.0169,  0.0243,  0.0289, -0.0548,  0.0793, -0.0686,\n",
       "                       -0.0251,  0.0777, -0.0537, -0.1359, -0.0550, -0.1276,  0.0878, -0.0002,\n",
       "                        0.0213,  0.1182, -0.0556,  0.0951,  0.1373, -0.0593, -0.0619,  0.0073,\n",
       "                        0.0843, -0.0528,  0.0414,  0.0742, -0.0652,  0.0450, -0.1215, -0.0612,\n",
       "                       -0.0602,  0.0086, -0.0359,  0.0713,  0.0928, -0.1345, -0.1394,  0.0547,\n",
       "                        0.0744,  0.0401,  0.1317,  0.0084, -0.0240,  0.0869,  0.0320,  0.0506,\n",
       "                        0.0047, -0.0350],\n",
       "                      [-0.0638,  0.0622, -0.1149, -0.1178, -0.0412, -0.0523,  0.0505, -0.0950,\n",
       "                        0.0196,  0.0793, -0.0192, -0.0297,  0.0180, -0.1356,  0.0134,  0.1009,\n",
       "                       -0.0152,  0.0112,  0.0246, -0.0359,  0.0305, -0.0050, -0.0623, -0.1228,\n",
       "                       -0.1209, -0.0819, -0.0706,  0.0264,  0.1065, -0.1043,  0.0671, -0.1156,\n",
       "                       -0.0356,  0.0824, -0.0243,  0.0317, -0.0845, -0.0761,  0.1118, -0.0645,\n",
       "                        0.1262,  0.0448, -0.1391, -0.0939,  0.1021,  0.1285, -0.0960,  0.0856,\n",
       "                        0.0452, -0.0568],\n",
       "                      [ 0.0424,  0.1225, -0.0238,  0.0836,  0.0220,  0.0190, -0.1111, -0.0707,\n",
       "                        0.0471, -0.0684,  0.1186,  0.1379,  0.0680, -0.0092,  0.0550,  0.0394,\n",
       "                        0.0570,  0.1129,  0.1026,  0.0250,  0.0061,  0.0854, -0.0208, -0.0470,\n",
       "                       -0.0586, -0.0994, -0.0232,  0.1367,  0.0514, -0.1051,  0.0493, -0.0499,\n",
       "                       -0.0260,  0.1138,  0.0975,  0.0904, -0.0165, -0.1243, -0.0507,  0.0388,\n",
       "                        0.1180,  0.0586, -0.0318,  0.1265,  0.1206, -0.0117, -0.1020,  0.0782,\n",
       "                       -0.1036, -0.0509]])),\n",
       "             ('net.2.bias',\n",
       "              tensor([-0.0050,  0.0247,  0.1334, -0.0731,  0.1180,  0.1129, -0.0400,  0.0640,\n",
       "                       0.0154,  0.1060,  0.1008,  0.0534, -0.1237, -0.0892, -0.1268,  0.0356,\n",
       "                       0.0790, -0.1188,  0.0045,  0.0994])),\n",
       "             ('net.4.weight',\n",
       "              tensor([[-0.9649, -0.4604,  0.2087,  0.8289, -0.5519,  0.5728,  1.0874,  1.9428,\n",
       "                       -0.5091, -0.1432,  0.3675, -0.6884,  0.1264,  1.5273,  0.2325, -0.9141,\n",
       "                        0.6474,  0.4486, -0.6136, -0.8484],\n",
       "                      [ 1.2326, -1.9754,  1.4029, -0.2245, -0.4036,  0.5824,  1.0319,  0.1920,\n",
       "                       -1.5855, -0.8494,  1.0415, -0.9114,  0.4546, -0.9986,  2.5507,  0.7619,\n",
       "                        0.7206, -0.3830,  1.3123,  0.2448]])),\n",
       "             ('net.4.bias', tensor([-1.8723,  0.5459]))])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1019b-faa3-4214-ba2d-4a8659e3f5f3",
   "metadata": {},
   "source": [
    "Logo, as duas primeiras camadas ((0) e (2)) são da rede anterior e a última camada ((4)) foi criada posteriormente. Desta forma, posso utilizar estas camadas na rede anterior ou em uma nova rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "08c69bf9-d1fd-40d9-b543-adaf960e66b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LazyLinear(in_features=0, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): LazyLinear(in_features=0, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utilizando na rede anterior:\n",
    "clone = MLP()                                    # instanciamos um clone do modelo MLP original  \\\n",
    "# clone.load_state_dict(torch.load('mlp.params'))  # lemos os parâmetros armazenados no arquivo diretamente.  \\\n",
    "clone.load_state_dict(camadas)  # lemos os parâmetros armazenados no arquivo diretamente.  \\\n",
    "clone.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4a8c147-a46b-479c-9ff4-a0d38b0e2354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LazyLinear(in_features=0, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): LazyLinear(in_features=0, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0f19deac-b9b4-4a21-877e-b87c975fd5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('net.0.weight', torch.Size([50, 100])),\n",
       " ('net.0.bias', torch.Size([50])),\n",
       " ('net.2.weight', torch.Size([20, 50])),\n",
       " ('net.2.bias', torch.Size([20])),\n",
       " ('net.4.weight', torch.Size([2, 20])),\n",
       " ('net.4.bias', torch.Size([2]))]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param.shape) for name, param in clone.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dce5057d-f2da-4f00-9123-e1fac73e7b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9255,  0.7424],\n",
       "        [-1.6536,  0.7815],\n",
       "        [-2.0473,  0.4035],\n",
       "        [-1.9340,  0.3080],\n",
       "        [-1.9688,  0.4775],\n",
       "        [-1.9776,  0.6307],\n",
       "        [-1.7683,  0.9331],\n",
       "        [-1.8743,  0.8061],\n",
       "        [-1.8371,  0.7640],\n",
       "        [-1.8530,  0.7020]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Posso colocar qualquer entrada X nesta rede:\n",
    "X = torch.rand(size=(10, 100))\n",
    "Y = clone(X)                        # Saída Y utilizando como entrada X\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a178c9f3-7894-4264-a344-ce471ab92fbd",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b6c01-c7d6-4d28-9192-2779cd28f7eb",
   "metadata": {},
   "source": [
    "# PARTE 3: UTILIZANDO AS CAMADAS APROVEITADAS/CRIADAS EM UMA NOVA REDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "acfa7a1e-7b42-45fa-ba83-5283be17190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOVA REDE:\n",
    "class NOVA(d2l.Classifier):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.LazyLinear(50),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(50,20),      # alterado de Lazy para Linear\n",
    "                                 nn.ReLU6(),            # alterado para ReLU6 \n",
    "                                 nn.LazyLinear(2)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "425127ed-ce7f-487e-b2b3-8269c17fefe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOVA(\n",
       "  (net): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): ReLU6()\n",
       "    (4): LazyLinear(in_features=0, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = NOVA()                                     # instanciamos um clone do modelo MLP original  \\\n",
    "# clone.load_state_dict(torch.load('mlp.params'))  # lemos os parâmetros armazenados no arquivo diretamente.  \\\n",
    "clone.load_state_dict(camadas)                     # lemos os parâmetros armazenados no arquivo diretamente.  \\\n",
    "clone.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "23827712-c38f-4e3a-860e-6a419c47fbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9299,  0.4467],\n",
       "        [-1.8426,  0.7746],\n",
       "        [-1.8470,  0.5628],\n",
       "        [-1.7955,  0.8536],\n",
       "        [-1.9411,  0.6458],\n",
       "        [-1.7669,  0.7647],\n",
       "        [-1.8334,  0.5955],\n",
       "        [-1.8755,  0.5875],\n",
       "        [-1.9239,  0.6542],\n",
       "        [-1.9461,  0.5672]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(size=(10, 100))\n",
    "Y = clone(X)                        # Saída Y utilizando a entrada X\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca9460-55ea-4f14-ba1a-38fc2a80c3db",
   "metadata": {},
   "source": [
    "# Ex.3 - Como você faria para salvar a arquitetura e os parâmetros da rede? Quais restrições você imporia à arquitetura?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0657f044-90b3-4de7-b0c0-d067b9e4f8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->net sem entradas:  MLP(\n",
      "  (net): Sequential(\n",
      "    (0): LazyLinear(in_features=0, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): LazyLinear(in_features=0, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): LazyLinear(in_features=0, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "-->Y:  tensor([[-0.0975,  0.0564],\n",
      "        [-0.0923,  0.0067],\n",
      "        [-0.1234,  0.0209],\n",
      "        [-0.0947,  0.0446],\n",
      "        [-0.1237,  0.0422],\n",
      "        [-0.0919,  0.0289],\n",
      "        [-0.0920,  0.0237],\n",
      "        [-0.0849,  0.0586],\n",
      "        [-0.0859,  0.0265],\n",
      "        [-0.1458,  0.0168]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "-->net com entradas:  MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# CLASSE PARA REDE SEM ENTRADAS (LazyLinear)\n",
    "class MLP(d2l.Classifier):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.LazyLinear(50),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.LazyLinear(20),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.LazyLinear(2)\n",
    "                                 )\n",
    "\n",
    "\n",
    "net = MLP()       # Rede sem entradas\n",
    "print(f'-->net sem entradas:  {net}\\n')\n",
    "\n",
    "\n",
    "X = torch.rand(size=(10, 100))    # Dados de entrada X\n",
    "Y = net(X)                        # Saída Y utilizando como entrada X\n",
    "print(f'-->Y:  {Y}\\n')\n",
    "\n",
    "print(f'-->net com entradas:  {net}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "44ef849d-c290-4446-954a-b05fd272ab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Save:\n",
    "# torch.save(net.state_dict(), 'mlp.params')          # copiando apenas parâmetros da rede\n",
    "\n",
    "# Save the model parameters to a separate file\n",
    "torch.save(net.state_dict(), 'mlp_parameters.pth')   # copiando os parâmetros aprendidos. Extensão: .pth. Vide referências.\n",
    "# A PTH file is a machine learning model\n",
    "\n",
    "# Save the model architecture to a script or JSON\n",
    "torch.save(net, 'mlp_arq.pth')                       # copiando a arquitetura  \n",
    "# A PTH file is a machine learning model \n",
    "\n",
    "\n",
    "# # Load:\n",
    "# clone = MLP()\n",
    "# clone.load_state_dict(torch.load('mlp.params'))\n",
    "# clone.eval()\n",
    "# print(f'-->clone:  {clone}\\n')\n",
    "\n",
    "\n",
    "net_new = torch.load('mlp_arq.pth')                     # carregando a rede completa\n",
    "# A PTH file is a machine learning model \n",
    "\n",
    "Y_new = net_new(X)\n",
    "Y_new == Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8026d0fe-d795-4774-a74c-01024938b440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_new.net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc9b0b-203b-4a4a-8fa8-9a171bd2b4f5",
   "metadata": {},
   "source": [
    "# Referências:\n",
    "\n",
    "https://pandalab.me/archives/file_io\n",
    "\n",
    "https://stackoverflow.com/questions/45114985/how-to-create-an-ordereddict-in-python \n",
    "\n",
    "https://stackoverflow.com/questions/24204087/how-to-get-multiple-dictionary-values\n",
    "\n",
    "https://fileinfo.com/extension/pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87a40c-f08b-4635-a3c0-e51ea6f782f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
